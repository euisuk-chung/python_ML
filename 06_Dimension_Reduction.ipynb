{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f873873b",
   "metadata": {},
   "source": [
    "\n",
    "# 차원 축소 알고리즘: PCA, t-SNE, UMAP\n",
    "차원 축소는 고차원 데이터를 저차원으로 변환하여 데이터의 구조를 더 잘 이해하고 시각화하는 데 도움을 주는 기법입니다. 이 글에서는 대표적인 차원 축소 알고리즘인 PCA, t-SNE, UMAP에 대해 정리하고, 각각의 알고리즘의 방법론, 장단점, 그리고 논문에 대해 소개합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfe6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('/mnt/data/creditcard.csv')\n",
    "\n",
    "# 데이터 기본 정보 확인\n",
    "data.info()\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터의 첫 몇 행 확인\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31236bb",
   "metadata": {},
   "source": [
    "\n",
    "## Class 분포 확인\n",
    "Class 컬럼의 분포를 시각화하여 데이터의 불균형 여부를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='Class', data=data)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913cc4c",
   "metadata": {},
   "source": [
    "\n",
    "## 특성 간 상관 관계 히트맵\n",
    "데이터의 특성 간 상관 관계를 히트맵으로 시각화하여 중요한 특성을 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(data.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02d5e3",
   "metadata": {},
   "source": [
    "\n",
    "## 데이터 전처리 및 스케일링\n",
    "Class 컬럼을 제외한 데이터의 스케일링을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6c72d",
   "metadata": {},
   "source": [
    "\n",
    "# 1. PCA (Principal Component Analysis)\n",
    "## 방법론\n",
    "PCA는 공분산 행렬을 기반으로 하는 matrix factorization 기법입니다. 고차원 데이터의 분산이 최대인 축을 찾아 그 축으로 데이터를 투영합니다. 첫 번째 주성분은 분산이 최대인 방향을 나타내고, 두 번째 주성분은 첫 번째 주성분과 직교하면서 분산이 최대인 방향을 나타냅니다. 이렇게 주성분들을 구하여 데이터를 저차원으로 변환합니다.\n",
    "\n",
    "## 장점\n",
    "- 간단하고 직관적입니다.\n",
    "- 데이터의 분산을 최대한 보존합니다.\n",
    "- 노이즈를 줄이는 데 효과적입니다.\n",
    "\n",
    "## 단점\n",
    "- 선형 변환에 기반하므로 비선형 구조를 잘 반영하지 못합니다.\n",
    "- 데이터가 뭉게질 수 있습니다.\n",
    "\n",
    "## 참고 논문\n",
    "- Pearson, K. (1901). \"On Lines and Planes of Closest Fit to Systems of Points in Space\". Philosophical Magazine.\n",
    "\n",
    "### 파이썬 코드 예시\n",
    "PCA를 사용하여 데이터를 2차원으로 축소하고 시각화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=y, cmap='viridis', alpha=0.5)\n",
    "plt.title('PCA Result')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2fbd8",
   "metadata": {},
   "source": [
    "\n",
    "PCA 결과를 해석하면, 데이터의 주성분이 최대 분산을 가진 방향으로 투영되어 있는 것을 볼 수 있습니다. 이 결과는 데이터의 전체적인 분포를 이해하는 데 도움이 되며, 주요 변동성을 나타내는 두 가지 축을 제공합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340fb10",
   "metadata": {},
   "source": [
    "\n",
    "# 2. t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
    "## 방법론\n",
    "t-SNE는 데이터의 국소적 이웃 구조를 보존하는 neighbor graph 기반의 기법입니다. 고차원 데이터의 유사성을 저차원에서도 유지하도록 변환합니다. t 분포를 사용하여 하나의 기준점과 다른 모든 데이터 간의 거리를 계산하고, 유사한 데이터끼리 묶어줍니다.\n",
    "\n",
    "## 장점\n",
    "- 데이터의 특징을 잘 가시화할 수 있습니다.\n",
    "- PCA와 같은 선형 변환 기법에서 발생하는 데이터 뭉개짐 문제를 해결합니다.\n",
    "- 하이퍼파라미터의 영향이 적고 이상치에 둔감합니다.\n",
    "\n",
    "## 단점\n",
    "- 연산 시간이 오래 걸립니다.\n",
    "- 높은 차원에서 바로 저차원으로 축소하기 어렵습니다.\n",
    "- 매번 실행할 때마다 다른 결과가 나올 수 있습니다.\n",
    "- 정보 손실로 인해 데이터 왜곡 가능성이 있습니다.\n",
    "\n",
    "## 참고 논문\n",
    "- Maaten, L. v. d., & Hinton, G. (2008). \"Visualizing Data using t-SNE\". Journal of Machine Learning Research.\n",
    "\n",
    "### 파이썬 코드 예시\n",
    "t-SNE를 사용하여 데이터를 2차원으로 축소하고 시각화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5981b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=y, cmap='viridis', alpha=0.5)\n",
    "plt.title('t-SNE Result')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.colorbar(label='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e0c17",
   "metadata": {},
   "source": [
    "\n",
    "# 3. UMAP (Uniform Manifold Approximation and Projection)\n",
    "## 방법론\n",
    "UMAP은 neighbor graph 기반의 기법으로, 고차원 공간의 데이터를 그래프로 만든 후 저차원으로 투영합니다. 이 과정은 리만 기하학과 위상수학에 기반하여 수학적으로 유효함이 증명되어 있습니다.\n",
    "\n",
    "## 장점\n",
    "- 빠른 연산 속도\n",
    "- 임베딩 차원의 크기에 대한 제한이 없습니다.\n",
    "- global structure를 잘 보존합니다.\n",
    "- 탄탄한 이론적 배경\n",
    "\n",
    "## 단점\n",
    "- 하이퍼파라미터의 영향을 크게 받습니다.\n",
    "- 저차원 임베딩 시 데이터 간 거리가 실제 거리와 일치하지 않을 수 있습니다.\n",
    "- 정보 손실로 인한 데이터 왜곡 가능성이 있습니다.\n",
    "\n",
    "## 참고 논문\n",
    "- McInnes, L., Healy, J., & Melville, J. (2018). \"UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\". arXiv preprint arXiv:1802.03426.\n",
    "\n",
    "### 파이썬 코드 예시\n",
    "UMAP을 사용하여 데이터를 2차원으로 축소하고 시각화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_result = umap_reducer.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(umap_result[:, 0], umap_result[:, 1], c=y, cmap='viridis', alpha=0.5)\n",
    "plt.title('UMAP Result')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.colorbar(label='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83971017",
   "metadata": {},
   "source": [
    "\n",
    "## 결론\n",
    "PCA, t-SNE, UMAP은 각각 고유한 장단점을 가지며, 데이터의 특성과 분석 목적에 따라 적절한 알고리즘을 선택하는 것이 중요합니다. 고차원 데이터를 다루는 다양한 프로젝트에서 이들 기법을 활용하여 효과적으로 차원을 축소하고 데이터를 이해할 수 있습니다. 각각의 알고리즘에 대한 좀 더 심도있는 내용은 추후에 개별 포스트로 한번 작성해보도록 하겠습니다.\n",
    "\n",
    "읽어주셔서 감사합니다 🤗\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
